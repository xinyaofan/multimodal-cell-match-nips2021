# multimodal-cell-match-nips2021


- Designed a novel deep network to learn matched cell modality embeddings. Employed customized convolutional layers
and self-attention modules followed by multi-modal cross-attention modules.
- Fine-tuned and trained proposed network using semi-hard triplet loss on 63K+ cells with 120K+ features.
- Decreased loss by 42% compared to baseline benchmark in test phase. Increased matching probability of individual cells
and cell types by 3x and 7x respectively on the testdata compared with baseline.


check the challenges and [dataset](https://openproblems.bio/neurips_2021/)

check the [slides](https://github.com/xinyaofan/multimodal-cell-match-nips2021/blob/main/slides_proposal/proposal_cpsc532s.pdf)
check the [proposal](https://github.com/xinyaofan/multimodal-cell-match-nips2021/blob/main/slides_proposal/proposal_cpsc532s.pdf)
