# multimodal-cell-match-nips2021


- Designed a novel deep network to learn matched cell modality embeddings. Employed customized convolutional layers
and self-attention modules followed by multi-modal cross-attention modules.
- Fine-tuned and trained proposed network using semi-hard triplet loss on 63K+ cells with 120K+ features.
- Decreased loss by 42% compared to baseline benchmark in test phase. Increased matching probability of individual cells
and cell types by 3x and 7x respectively on the testdata compared with baseline.


check the [dataset](https://openproblems.bio/neurips_2021/)

check the [slides](https://github.com/xinyaofan/multimodal-cell-match-nips2021/blob/main/slides_proposal/proposal_cpsc532s.pdf)
check the [proposal](https://github.com/xinyaofan/multimodal-cell-match-nips2021/blob/main/slides_proposal/proposal_cpsc532s.pdf)
